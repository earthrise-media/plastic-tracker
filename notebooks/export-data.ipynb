{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df, num_sources=None, num_targets=None):\n",
    "    \"\"\"\n",
    "    A function to filter the data frame by top n sources and targets\n",
    "    If num_sources or num_targets args are not supplied, they will not be filtered\n",
    "    \"\"\"\n",
    "    if num_targets:\n",
    "        top_targets = df.sum().sort_values(ascending=False)\n",
    "        df = df[top_targets[:num_targets].index]\n",
    "    \n",
    "    if num_sources:\n",
    "        top_sources = df.sum(axis=1).sort_values(ascending=False)[:num_sources]\n",
    "        df = df.loc[top_sources.index]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_sankey_df(df, min_val=0):\n",
    "    \"\"\"\n",
    "    Create the human-readable form of the Sankey chart data from an input data frame\n",
    "    Data can be filtered by a threshold minimum value\n",
    "    | Source | Source Value | Target | Target Value |\n",
    "    |    A   |      5       |   i    |      3       |\n",
    "    |    A   |      5       |   j    |      2       |\n",
    "    |    B   |      7       |   i    |      1       |\n",
    "    |    B   |      7       |   k    |      4       |\n",
    "    \"\"\"\n",
    "    \n",
    "    sources = []\n",
    "    source_vals = []\n",
    "    targets = []\n",
    "    target_vals = []\n",
    "    for source_name in df.index:\n",
    "        row = df.loc[source_name]\n",
    "        sources += [source_name] * sum(row.values > min_val)\n",
    "        source_vals += [row[row.values > min_val].sum()] * sum(row.values > min_val)\n",
    "        targets += list(row[row > min_val].index)\n",
    "        target_vals += list(row[row > min_val].values)\n",
    "    \n",
    "    sankey_df = pd.DataFrame({\n",
    "        'source': sources,\n",
    "        'target': targets,\n",
    "        'value': target_vals\n",
    "    })\n",
    "    \n",
    "    return sankey_df\n",
    "\n",
    "\n",
    "def create_label_dict(node_df, start_idx=0):\n",
    "    \"\"\"\n",
    "    Return a dictionary with labels as keys and indices as values.  Applied \n",
    "    to each section of the flow visualization (two nodes and an edge). The\n",
    "    `node_df` represents each section.\n",
    "    \"\"\"\n",
    "    labels = set(node_df.source).union(node_df.target)\n",
    "    sorted_labels = sorted(list(labels))\n",
    "    return {sorted_labels[i]: i + start_idx for i in range(len(sorted_labels))}\n",
    "\n",
    "\n",
    "def create_final_list(node_df, node_label_dict):\n",
    "    \"\"\"\n",
    "    Return a list of dictionaries and the labels for each section of the flow \n",
    "    diagram.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({\n",
    "        \"source\": node_df.source.map(node_label_dict),\n",
    "        \"target\": node_df.target.map(node_label_dict),\n",
    "        \"value\" : node_df.value\n",
    "    })\n",
    "    \n",
    "    labels = list(node_label_dict.keys())\n",
    "    return df.to_dict(\"records\"), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "investor = pd.read_excel(\n",
    "    \"../data/Equity investor SUP matrix.xlsx\",\n",
    "    engine=\"openpyxl\",\n",
    "    skiprows=3,\n",
    "    usecols=\"B, E:GG\",\n",
    ")\n",
    "\n",
    "investor = investor.rename(columns={investor.columns[0]: \"Ultimate Investor\"})\n",
    "\n",
    "# drop last row because it is a table summary\n",
    "investor = investor[:-1]\n",
    "investor = investor.set_index('Ultimate Investor')\n",
    "\n",
    "# Set the value of Kingdom of Saudi Arabia investment in Saudi Arabian Oil company to equal\n",
    "# the second largest investment\n",
    "investor.loc['KINGDOM OF SAUDI ARABIA', ('Saudi Arabian Oil Co')] = investor.max(axis=0).sort_values(ascending=False)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financer = pd.read_excel(\n",
    "    \"../data/Financing SUP matrix.xlsx\",\n",
    "    engine=\"openpyxl\",\n",
    "    skiprows=4,\n",
    "    usecols=\"A:AV\",\n",
    ")\n",
    "\n",
    "# drop last row because it is null\n",
    "financer = financer[:-1]\n",
    "financer = financer.set_index('Bank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = pd.read_excel(\n",
    "    \"../data/MFA matrix.xlsx\",\n",
    "    sheet_name=\"Conversion\",\n",
    "    engine=\"openpyxl\",\n",
    "    skiprows=1,\n",
    "    usecols=\"C:FY\",\n",
    ").dropna()\n",
    "\n",
    "producer = producer.groupby('Producer').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waste = pd.read_excel(\n",
    "    \"../data/MFA matrix.xlsx\",\n",
    "    sheet_name=\"Waste\",\n",
    "    engine=\"openpyxl\",\n",
    "    skiprows=1,\n",
    "    usecols=\"B, D:FY\",\n",
    ").dropna()\n",
    "\n",
    "waste = waste.groupby('Country').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination = pd.read_excel(\n",
    "    \"../data/MFA matrix.xlsx\",\n",
    "    sheet_name=\"Waste\",\n",
    "    engine=\"openpyxl\",\n",
    "    skiprows=1,\n",
    "    usecols=\"C:FY\",\n",
    ").dropna()\n",
    "\n",
    "destination = destination.groupby('Producer').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "investor_df = create_sankey_df(investor)\n",
    "financier_df = create_sankey_df(financer)\n",
    "producer_df = create_sankey_df(producer)\n",
    "waste_df = create_sankey_df(waste)\n",
    "destination_df = create_sankey_df(destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Important!* Choose to export either `investor` or `financier` dataset here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = 'investor'\n",
    "dataset = 'financier'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export JSON for D3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate two (or more) dataframes together\n",
    "\n",
    "if dataset == 'investor':\n",
    "    df_1 = investor_df\n",
    "if dataset == 'financier':\n",
    "    df_1 = financier_df\n",
    "else:\n",
    "    print(\"Choose either 'investor' or 'financier' as the dataset type\")\n",
    "\n",
    "df_2 = destination_df\n",
    "\n",
    "full_df = pd.concat([df_1, df_2], ignore_index=True)\n",
    "\n",
    "column_dict = {name: 1 for name in np.unique(df_1['source']) }\n",
    "for name in np.unique(pd.concat([df_1['target'], df_2['source']])):\n",
    "    column_dict[name] = 2\n",
    "for name in np.unique(df_2['target']):\n",
    "    column_dict[name] = 3\n",
    "    \n",
    "# For every unique name in dataframe, create a name to index dictionary\n",
    "labels = np.unique([[full_df['source']] + [full_df['target']]])\n",
    "total_idx_dict = { labels[i]: i for i in range(len(labels)) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate base structure for dataset and populate links\n",
    "full_d3_dataset = {\n",
    "    'links': [],\n",
    "    'nodes': []\n",
    "}\n",
    "\n",
    "for src, tar, val in zip(list(full_df.source.map(total_idx_dict)), \n",
    "                         list(full_df.target.map(total_idx_dict)), \n",
    "                         list(full_df.value)):\n",
    "    full_d3_dataset['links'].append({\n",
    "        \"source\": src,\n",
    "        \"target\": tar,\n",
    "        \"value\": round(val, 3)\n",
    "    })\n",
    "\n",
    "for label in labels:\n",
    "    full_d3_dataset['nodes'].append({\n",
    "        \"name\": label,\n",
    "        \"column\": column_dict[label],\n",
    "        \"hover\": {},\n",
    "        \"locations\": []\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Hover Label Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add investor value data\n",
    "investor_value = pd.read_excel(\n",
    "    \"../data/Equity investor SUP matrix.xlsx\",\n",
    "    engine=\"openpyxl\",\n",
    "    skiprows=3,\n",
    "    usecols=\"B, GH\",\n",
    ")\n",
    "\n",
    "investor_value = investor_value.rename(columns={investor_value.columns[0]: \"Ultimate Investor\"})\n",
    "investor_value = investor_value[:-1]\n",
    "investor_value = investor_value.set_index('Ultimate Investor')\n",
    "\n",
    "for name in investor_value.index:\n",
    "    node_names = [node['name'] for node in full_d3_dataset['nodes']]\n",
    "    if name in node_names:\n",
    "        d3_node_index = node_names.index(name)\n",
    "        value = investor_value.loc[name]['Holding - Single Use Plastic Adjusted (USD mn)']\n",
    "        full_d3_dataset['nodes'][d3_node_index]['hover']['Total Value'] = round(value, 3)\n",
    "\n",
    "        \n",
    "# Add investor volume data\n",
    "investor_volume = pd.read_excel(\n",
    "    \"../data/Equity investor SUP footprint matrix.xlsx\",\n",
    "    engine=\"openpyxl\",\n",
    "    skiprows=3,\n",
    "    usecols=\"B, CV\",\n",
    ")\n",
    "\n",
    "investor_volume = investor_volume.rename(columns={investor_volume.columns[0]: \"Ultimate Investor\"})\n",
    "investor_volume = investor_volume[:-1]\n",
    "investor_volume = investor_volume.set_index('Ultimate Investor')\n",
    "\n",
    "for name in investor_volume.index:\n",
    "    node_names = [node['name'] for node in full_d3_dataset['nodes']]\n",
    "    if name in node_names:\n",
    "        d3_node_index = node_names.index(name)\n",
    "        value = investor_volume.loc[name]['Footprint (kt)']\n",
    "        full_d3_dataset['nodes'][d3_node_index]['hover']['Total Volume'] = round(value, 3)\n",
    "\n",
    "        \n",
    "# Add financer value data\n",
    "financer_value = pd.read_excel(\n",
    "    \"../data/Financing SUP matrix.xlsx\",\n",
    "    engine=\"openpyxl\",\n",
    "    skiprows=4,\n",
    "    usecols=\"A:AV\",\n",
    ")\n",
    "\n",
    "financer_value = financer[:-1]\n",
    "financer_value = financer_value.sum(axis=1)\n",
    "for name in financer_value.index:\n",
    "    node_names = [node['name'] for node in full_d3_dataset['nodes']]\n",
    "    if name in node_names:\n",
    "        d3_node_index = node_names.index(name)\n",
    "        value = financer_value[name]\n",
    "        full_d3_dataset['nodes'][d3_node_index]['hover']['Total Value'] = round(value, 3)        \n",
    "\n",
    "\n",
    "# Add producer volume label\n",
    "producer_total_volume = pd.read_excel(\n",
    "    \"../data/MFA matrix.xlsx\",\n",
    "    sheet_name=\"Pivot - Waste\",\n",
    "    engine=\"openpyxl\",\n",
    "    skiprows=2,\n",
    "    usecols=\"A:B\",\n",
    ").dropna().set_index('Row Labels')\n",
    "\n",
    "for name in producer_total_volume.index:\n",
    "    node_names = [node['name'] for node in full_d3_dataset['nodes']]\n",
    "    if name in node_names:\n",
    "        d3_node_index = node_names.index(name)\n",
    "        value = producer_total_volume.loc[name]['Sum of checksum']\n",
    "        full_d3_dataset['nodes'][d3_node_index]['hover']['Total Volume'] = round(value, 3) \n",
    "\n",
    "\n",
    "# Add producer equity value label\n",
    "equity_value = pd.read_excel(\n",
    "    \"../data/Equity investor SUP matrix.xlsx\",\n",
    "    engine=\"openpyxl\",\n",
    "    skiprows=3,\n",
    "    usecols=\"B, E:GG\",\n",
    ")\n",
    "\n",
    "equity_value = equity_value.rename(columns={equity_value.columns[0]: \"Ultimate Investor\"})\n",
    "equity_value = equity_value[:-1]\n",
    "equity_value = equity_value.set_index('Ultimate Investor')\n",
    "equity_value = equity_value.sum()\n",
    "equity_value.head()\n",
    "\n",
    "for name in equity_value.index:\n",
    "    node_names = [node['name'] for node in full_d3_dataset['nodes']]\n",
    "    if name in node_names:\n",
    "        d3_node_index = node_names.index(name)\n",
    "        value = equity_value[name]\n",
    "        full_d3_dataset['nodes'][d3_node_index]['hover']['Equity Value'] = round(value, 3)\n",
    "        \n",
    "        \n",
    "# Add circularity score label\n",
    "circularity = pd.read_excel(\n",
    "    \"../data/CA matrix.xlsx\",\n",
    "    sheet_name='Circularity Assessment',\n",
    "    engine=\"openpyxl\",\n",
    "    skiprows=1,\n",
    "    usecols=\"D, F\",\n",
    ").dropna().set_index('Polymer producers ranked by circularity score')\n",
    "\n",
    "for name in circularity.index:\n",
    "    node_names = [node['name'] for node in full_d3_dataset['nodes']]\n",
    "    if name in node_names:\n",
    "        d3_node_index = node_names.index(name)\n",
    "        value = circularity.loc[name]['Circularity\\nscore']\n",
    "        full_d3_dataset['nodes'][d3_node_index]['hover']['Circularity Score'] = value\n",
    "\n",
    "\n",
    "# Add total financing value label\n",
    "financer = pd.read_excel(\n",
    "    \"../data/Financing SUP matrix.xlsx\",\n",
    "    engine=\"openpyxl\",\n",
    "    skiprows=4,\n",
    "    usecols=\"A:AV\",\n",
    ")\n",
    "financer = financer[:-1]\n",
    "financer = financer.set_index('Bank')\n",
    "financing_total = financer.sum()\n",
    "\n",
    "for name in financing_total.index:\n",
    "    node_names = [node['name'] for node in full_d3_dataset['nodes']]\n",
    "    if name in node_names:\n",
    "        d3_node_index = node_names.index(name)\n",
    "        value = financing_total[name]\n",
    "        full_d3_dataset['nodes'][d3_node_index]['hover']['Total Financing'] = round(value, 3)\n",
    "        \n",
    "        \n",
    "# Add total waste label\n",
    "total_waste = pd.read_excel(\n",
    "    \"../data/MFA matrix.xlsx\",\n",
    "    sheet_name=\"Waste\",\n",
    "    engine=\"openpyxl\",\n",
    "    skiprows=1,\n",
    "    usecols=\"B:C, D:FY\",\n",
    ").dropna()\n",
    "total_waste = total_waste.groupby('Producer').sum()\n",
    "total_waste = total_waste.sum()\n",
    "\n",
    "for name in total_waste.index:\n",
    "    node_names = [node['name'] for node in full_d3_dataset['nodes']]\n",
    "    if name in node_names:\n",
    "        d3_node_index = node_names.index(name)\n",
    "        value = total_waste[name]\n",
    "        full_d3_dataset['nodes'][d3_node_index]['hover']['Total Waste'] = round(value, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign Regions to Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/region_map.json', 'r') as f:\n",
    "    region_dict = json.load(f)\n",
    "country_to_region = { country['name']: country['region'] for country in region_dict }\n",
    "\n",
    "for node in full_d3_dataset['nodes']:\n",
    "    if node['name'] in country_to_region.keys():\n",
    "        node['region'] = country_to_region[node['name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nodes without a matched region:\", [node['name'] for node in full_d3_dataset['nodes'] if 'region' not in list(node.keys()) and node['column'] == 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Producer Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = pd.read_csv('../data/producer_locations.csv')\n",
    "\n",
    "node_names = [node['name'] for node in full_d3_dataset['nodes']]\n",
    "for index in range(len(locations)):\n",
    "    row = locations.loc[index]\n",
    "    producer_name = row['Producer name']\n",
    "    lon = row['city_lon']\n",
    "    lat = row['city_lat']\n",
    "    coords = []\n",
    "    if producer_name in node_names:\n",
    "        d3_node_index = node_names.index(producer_name)\n",
    "        full_d3_dataset['nodes'][d3_node_index]['locations'].append([lat, lon])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Node Data and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_d3_dataset['nodes'][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'investor':\n",
    "    with open('../data/d3/investor-producer-destination_labels_coords_regions.json', 'w') as f:\n",
    "        json.dump(full_d3_dataset, f)\n",
    "if dataset == 'financier':\n",
    "    with open('../data/d3/financier-producer-destination_labels_coords_regions.json', 'w') as f:\n",
    "        json.dump(full_d3_dataset, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
